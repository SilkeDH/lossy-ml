{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner import HyperModel\n",
    "from tensorflow.keras.layers import Conv3D, Conv3DTranspose, ReLU, Activation, Input, Reshape, Flatten, Dense, PReLU, ReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import dask\n",
    "from collections import OrderedDict\n",
    "from lossycomp.dataLoader import DataGenerator, data_preprocessing, split_data\n",
    "from lossycomp.utils import lr_log_reduction, correlation_5, calculate_MAE_5, mean_squared_error_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder_2(HyperModel):\n",
    "    def __init__(self, time, latitude, longitude, channels, strides = 2):\n",
    "        self.time = time\n",
    "        self.latitude = latitude\n",
    "        self.longitude = longitude\n",
    "        self.channels = channels\n",
    "        self.strides = strides\n",
    "    \n",
    "    def build(self, hp):\n",
    "        \n",
    "        def ResBlock(x, num_filter):\n",
    "            x_in = x\n",
    "            x = Conv3D(num_filter, (3, 3, 3), strides = (1, 1, 1), padding=\"same\", kernel_regularizer= tf.keras.regularizers.l2(hp6))(x)\n",
    "            x = ReLU()(x)\n",
    "            x = Conv3D(num_filter, (3, 3, 3), strides = (1, 1, 1), padding=\"same\", kernel_regularizer= tf.keras.regularizers.l2(hp6))(x)\n",
    "            x = x_in + x\n",
    "            x = ReLU()(x)\n",
    "            return x\n",
    "    \n",
    "        inputShape = (self.time, self.latitude, self.longitude, self.channels)\n",
    "        # Input to the encoder\n",
    "        inputs = Input(shape=inputShape)\n",
    "        x = inputs\n",
    "        \n",
    "\t\t# Define hyperparameters\n",
    "\t\t\n",
    "        hp1 = hp.Int('convs', min_value= 4, max_value= 5, step=1)  # Hyp 1: Number of convolutions [4,5,6]\n",
    "      \n",
    "        hp2 = hp.Choice('filter', values=[20, 32, 64]) # Hyp 2: Number of filters.\n",
    "        \n",
    "        hp3 = hp.Int('kernel_siz', min_value=3, max_value= 7, step=1) #Hyp 3: Kernel size [3,4,5,6,7]\n",
    "\t\t\n",
    "        hp4 = hp.Float('Learning_rate', min_value = 0.0001, max_value = 0.01, sampling = 'log') # Hyp 4: Learning rate (0.01, 0.0001)\n",
    "\n",
    "        hp5 = hp.Int('num_res_blocks', 0, 3) # Hyp 5: Number of residual blocks [0,1,2,3]\n",
    "        \n",
    "        hp6 = hp.Float('l2_reg', min_value = 0.00005 , max_value = 0.5, sampling = 'log' ) # Hyp 6: Number of residual blocks [0,1,2,3]\n",
    "\t\t\n",
    "        x = Conv3D(hp2, (hp3, hp3, hp3), strides = (1,1, 1) , padding=\"same\", kernel_regularizer= tf.keras.regularizers.l2(hp6), activation = 'relu')(x)\n",
    "        \n",
    "\t\t# Residual Blocks\n",
    "        for i in range(hp5):\n",
    "            x = ResBlock(x, hp2)\n",
    "        \n",
    "        for i in range(hp1):\n",
    "            x = Conv3D(hp2, (hp3, hp3, hp3), strides = (self.strides,self.strides,self.strides) , padding=\"same\", kernel_regularizer= tf.keras.regularizers.l2(hp6), activation = 'relu')(x)\n",
    "        \n",
    "        volumeSize = K.int_shape(x)\n",
    "    \n",
    "        encoder = Model(inputs = inputs, outputs = x, name=\"Encoder\")\n",
    "      \n",
    "        # Input to the decoder\n",
    "        latentInputs = Input(shape=volumeSize[1:])\n",
    "        \n",
    "        x = latentInputs\n",
    "        \n",
    "        for i in range(hp1-1):\n",
    "            x = Conv3DTranspose(hp2, (hp3, hp3, hp3), strides = (self.strides,self.strides,self.strides) , padding=\"same\", kernel_regularizer= tf.keras.regularizers.l2(hp6), activation = 'relu')(x)\n",
    "        \n",
    "        for i in range(hp5):\n",
    "            x = ResBlock(x, hp2)\n",
    "        \n",
    "        x = Conv3DTranspose(filters = 1, kernel_size = (hp3, hp3, hp3),\n",
    "                            activation=None, strides = 2 , padding=\"same\", kernel_regularizer= tf.keras.regularizers.l2(hp6))(x)  \n",
    "\n",
    "        # build the decoder model\n",
    "        decoder = Model(latentInputs, x, name=\"Decoder\")\n",
    "        autoencoder = Model(inputs, decoder(encoder(inputs)), name=\"Autoencoder\")\n",
    "            \n",
    "        autoencoder.compile(optimizer=keras.optimizers.Adam(hp4),\n",
    "                      loss=mean_squared_error_5, \n",
    "                      metrics=[ tf.keras.losses.MeanSquaredError(), 'MAE']) \n",
    "        print(autoencoder.summary())\n",
    "        return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypermodel = Autoencoder_2(32, 64, 64, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project 5_channel/climate_model/oracle.json\n",
      "Model: \"Autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 64, 64, 5)]   0         \n",
      "_________________________________________________________________\n",
      "Encoder (Functional)         (None, 2, 4, 4, 20)       46000     \n",
      "_________________________________________________________________\n",
      "Decoder (Functional)         (None, 32, 64, 64, 1)     33001     \n",
      "=================================================================\n",
      "Total params: 79,001\n",
      "Trainable params: 79,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch(\n",
    "    hypermodel,\n",
    "    objective='val_loss',\n",
    "    max_trials=50,\n",
    "    directory='5_channel',\n",
    "    project_name='climate_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 6\n",
      "convs (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 4, 'max_value': 5, 'step': 1, 'sampling': None}\n",
      "filter (Choice)\n",
      "{'default': 20, 'conditions': [], 'values': [20, 32, 64], 'ordered': True}\n",
      "kernel_siz (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 3, 'max_value': 7, 'step': 1, 'sampling': None}\n",
      "Learning_rate (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n",
      "num_res_blocks (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 0, 'max_value': 3, 'step': 1, 'sampling': None}\n",
      "l2_reg (Float)\n",
      "{'default': 5e-05, 'conditions': [], 'min_value': 5e-05, 'max_value': 0.5, 'step': None, 'sampling': 'log'}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data into RAM\n",
      "Loading data into RAM\n"
     ]
    }
   ],
   "source": [
    "dask.config.set(**{'array.slicing.split_large_chunks': False})\n",
    "\n",
    "file = '/lsdf/kit/scc/projects/abcde/1979/*/ERA5.pl.temperature.nc'\n",
    "region = \"globe\"\n",
    "var = OrderedDict({'t': 1000})\n",
    "\n",
    "z, mean, std = data_preprocessing(file, var, region)\n",
    "\n",
    "train, test = split_data(z, 0.70)\n",
    "\n",
    "leads = dict(time = 32, longitude=64, latitude=64, level=1)\n",
    "\n",
    "dg_train = DataGenerator(z, 10000, leads, batch_size=10, load=True, mean= mean, std=std, coords = True, standardize = True) \n",
    "dg_test = DataGenerator(test, 100, leads, batch_size=10, load=True, mean= mean, std=std, coords = True, standardize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "convs             |5                 |?                 \n",
      "filter            |20                |?                 \n",
      "kernel_siz        |4                 |?                 \n",
      "Learning_rate     |0.0022171         |?                 \n",
      "num_res_blocks    |3                 |?                 \n",
      "l2_reg            |0.014748          |?                 \n",
      "\n",
      "Model: \"Autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 64, 64, 5)]   0         \n",
      "_________________________________________________________________\n",
      "Encoder (Functional)         (None, 1, 2, 2, 20)       199440    \n",
      "_________________________________________________________________\n",
      "Decoder (Functional)         (None, 32, 64, 64, 1)     168681    \n",
      "=================================================================\n",
      "Total params: 368,121\n",
      "Trainable params: 368,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "   2/1000 [..............................] - ETA: 2:09 - loss: 22.0387 - mean_squared_error: 2.4128 - MAE: 1.0570WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0834s vs `on_train_batch_end` time: 0.1760s). Check your callbacks.\n",
      " 937/1000 [===========================>..] - ETA: 15s - loss: 12.4120 - mean_squared_error: 2.0419 - MAE: 1.0050"
     ]
    }
   ],
   "source": [
    "tuner.search(dg_train, epochs=100,  validation_data=dg_test,  callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
